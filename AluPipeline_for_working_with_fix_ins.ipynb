{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SHORT DESCRIPTION\n",
    "\n",
    "* NCORE - numbers of core. For parallel pipeline NCORE > 1 (max NCORE = 8)\n",
    "* DELETE_NOW - If True, bad reads (by filters) will be deleted after each filter\n",
    "* IS_SHORT_FLANK - If True, ignore additional PRIMER and AD1 in R1\n",
    "* CHAOS - If True, you're not sure that file(R1) is contained R1 and file(R2) is contained R2\n",
    "* MIN_READ - Create own FIX and dbRIP file for each library (if NUM_READS >= MIN_READ)\n",
    "* INSWINDOW_FIX - Delete reads if CURRENT_POS ~ [RESTRICT_SITE : IS + INSWINDOWS_FIX] (for INS_STRAND = +)\n",
    "* SHIFT_RESTRICT_SITE - Mark reads if RESTRICT_SITE was found in [RESTRICT_SITE :  IS + SHIFT] (for INS_STRAND = +)\n",
    "* SHIFT_MISS_PRIMER - Mark reads if PRIMER was found in [IS :  IS + SHIFT] (for INS_STRAND = +)\n",
    "* SHIFT_MISS_RE -  Mark reads if PRIMER was found in [IS :  IS + SHIFT] (for INS_STRAND = +)\n",
    "* RE_HAMMING - Delete reads RE_HAMMING_CURRENT >= RE_HAMMING\n",
    "* FLANK_ERRORS - Delete reads FLANK_ERRORS_CURRENT >= FLANK_ERRORS\n",
    "* REPEAT - Delete reads REPEAT_CURRENT >= REPEAT\n",
    "* MISS_PRIMER - Delete reads MISS_PRIMER_CURRENT <= MISS_PRIMER\n",
    "* MISS_RE - Delelte reads MISS_RE_CURRENT <= MISS_RE\n",
    "* TEMPLATE_SWITCH_MD - Delete reads MDMATCH >= TEMPLATE_SWITCH_MD\n",
    "* WINDOW - Window for megaclustering\n",
    "* MAIN_FLAN_LEN - For template switch. TARGET_READS = PRIMER + RE + MAIN_FLAN_LEN(of R1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/Komar/Lab/retroparty\n",
      "/mnt/c/Users/Komar/Lab\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())\n",
    "os.chdir('/mnt/c/Users/Komar/Lab/')\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PATHWAYS\n",
    "lll = '''\n",
    "INPUTDIR = '/mnt/c/Users/Komar/Lab/InPutDir/artificial_data_multiUMI'\n",
    "OUTPUTDIR = '/mnt/c/Users/Komar/Lab/OutPutDir/artificial_multiUMI'\n",
    "\n",
    "MAPPER = 'bowtie2' #bwa or bowtie2\n",
    "BOWTIE_INDEX = '/mnt/c/Users/Komar/Lab/UCSC_hg38/ref_bowtie2_index'\n",
    "BWA_INDEX = '/mnt/c/Users/Komar/Lab/UCSC_hg38/ref_bwa_index'\n",
    "\n",
    "ALU_REF_LIB = '/mnt/c/Users/Komar/Lab/retroparty/Alu_replibrary_hg38.txt'  # fixed and polymorphic Alu insertions \n",
    "REF_GENOME = '/mnt/c/Users/Komar/Lab/UCSC_hg38/genome.fa'\n",
    "REPEATS_REF_LIB = '/mnt/c/Users/Komar/Lab/retroparty/repeats_hg38.tabular'  # all known fixed repeats\n",
    "\n",
    "#SYS PARAMETRS\n",
    "NCORE = 8  # threads\n",
    "\n",
    "#PREPROCESSING\n",
    "PRIMER = 'GAGCCACCGCGC'\n",
    "SHIFT = 5\n",
    "MIST = 1\n",
    "AD1 = 'GCGTGCTGCGG'\n",
    "AD2 = 'AGGGCGGT'\n",
    "BLEN = 9\n",
    "RE = 'CCGGCC'\n",
    "RESTRICT_SITE = {'AGCT': 'CT', 'TCGA': 'GA'} # {'GTAC': 'TAC', 'CTAG': 'TAG'} # {'restrict site': 'r2_start'}\n",
    "IS_SHORT_FLANK = False\n",
    "CHAOS = True\n",
    "TRIMM_N = 0\n",
    "TRIMM_POLY_N = False\n",
    "POLY_N_R1 = (15, 0.8, 7) # poly_n_win_size_r1, poly_n_th_r1, poly_n_shift_r1\n",
    "POLY_N_R2 = (15, 0.8, 7) # poly_n_win_size_r2, poly_n_th_r2, poly_n_shift_r2\n",
    "SKIP_SHORT_READS = 50\n",
    "MID_MIST_SHORT_READS = (3, 2) # (r1 ,r2) max mismatches in AD2 or PRIMER which will remove from reads\n",
    "END_MIST_SHORT_READS = (6, 6) # (r1 ,r2) min length of AD2 or PRIMER at the reads ends\n",
    "PLACE_OF_SEARCH_TAIL = (None, None) # (r1 ,r2)\n",
    "MIN_SEQ_LEN_AFTER_TRIMM = (25, 25) # (r1 ,r2)\n",
    "\n",
    "#SAMFILTER\n",
    "FLAGS = [99, 83, 147, 163] # + [355, 339, 403, 419]\n",
    "\n",
    "R_SITE_DISTANCE = 1000\n",
    "\n",
    "#FILTERS\n",
    "FIX_WINDOW = 1\n",
    "MIN_READ = 1\n",
    "MAX_DIST = 1000\n",
    "MIN_DIST = 0\n",
    "INSWINDOW_FIX = 40\n",
    "SHIFT_RESTRICT_SITE = 3 \n",
    "SHIFT_MISS_PRIMER = 27\n",
    "SHIFT_MISS_RE = 9\n",
    "\n",
    "#THRESHOLDS\n",
    "RE_HAMMING = 2\n",
    "FLANK_ERRORS = 5\n",
    "REPEAT = 0.8\n",
    "MISS_PRIMER = 4\n",
    "MISS_RE = 2\n",
    "TEMPLATE_SWITCH_MD = 30\n",
    "\n",
    "#METACLUSTERING\n",
    "WINDOW = 100\n",
    "MAIN_FLANK_LEN = 11 # template switch?  #'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len('CATATGTAACTAACCTGCACAATGT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "#PATHWAYS\n",
    "INPUTDIR = '/mnt/c/Users/Komar/Lab/InPutDir/test_L' # sys.argv[1]  # '/home/common/komarov.na/data/artificial_multi'\n",
    "OUTPUTDIR = '/mnt/c/Users/Komar/Lab/OutPutDir/test_L_2'  # sys.argv[2]  #  '/home/common/komarov.na/results/artificial_multi'\n",
    "\n",
    "MAPPER = 'bowtie2' #bwa or bowtie2\n",
    "BOWTIE_INDEX = '/mnt/c/Users/Komar/Lab/UCSC_hg38/ref_bowtie2_index'\n",
    "BWA_INDEX = '/mnt/c/Users/Komar/Lab/UCSC_hg38/ref_bwa_index'\n",
    "\n",
    "ALU_REF_LIB = '/mnt/c/Users/Komar/Lab/UCSC_hg38/Human_L1_coord_hg38.txt'  # fixed and polymorphic target repeat insertions\n",
    "REF_GENOME = '/mnt/c/Users/Komar/Lab/UCSC_hg38/genome.fa'\n",
    "REPEATS_REF_LIB = '/mnt/c/Users/Komar/Lab/UCSC_hg38/repeats_hg38.tabular'  # all known fixed repeats\n",
    "\n",
    "#SYS PARAMETRS\n",
    "NCORE = 4  # threads\n",
    "\n",
    "#PREPROCESSING\n",
    "# LINE HaeIII\n",
    "PRIMER = 'CATATGTAACTAACCTGCACAATGTGCACATGTACCCTAAAACTTAAAGTAT' #52 # 'GTGAGCCACCGCGC'\n",
    "SHIFT = 5\n",
    "MIST = 2\n",
    "AD1 = 'AGGGCGTGGTGCGG' #'AGGGCGAG'  #'AGGGCGTGGTGCGG'\n",
    "AD2 = 'AGGGCGG'  #'AGGGCGGT'\n",
    "BLEN = 0\n",
    "RE = 'AATAAA' #'CCGGCC'\n",
    "\n",
    "#argumentList = sys.argv[3].split('_')\n",
    "RESTRICT_SITE = {'GGCC': 'CC'}\n",
    "            #{'GTAC':'AC', 'AGCT': 'CT'} # {'GTAC': 'TAC', 'CTAG': 'TAG'} # {'restrict site': 'r2_start'}\n",
    "IS_SHORT_FLANK = True\n",
    "CHAOS = True\n",
    "TRIMM_N = 0\n",
    "TRIMM_POLY_N = True\n",
    "POLY_N_R1 = (15, 0.8, 30) # poly_n_win_size_r1, poly_n_th_r1, poly_n_shift_r1\n",
    "POLY_N_R2 = (15, 0.8, 30) # poly_n_win_size_r2, poly_n_th_r2, poly_n_shift_r2\n",
    "SKIP_SHORT_READS = 60\n",
    "MID_MIST_SHORT_READS = (1, 2) # (r1 ,r2) max mismatches in AD2 or PRIMER which will remove from reads\n",
    "END_MIST_SHORT_READS = (5, 5) # (r1 ,r2) min length of AD2 or PRIMER at the reads ends\n",
    "PLACE_OF_SEARCH_TAIL = (None, None) # (r1 ,r2)\n",
    "MIN_SEQ_LEN_AFTER_TRIMM = (25, 25) # (r1 ,r2)\n",
    "\n",
    "#SAMFILTER\n",
    "FLAGS = [99, 83, 147, 163] # + [355, 339, 403, 419]\n",
    "\n",
    "R_SITE_DISTANCE = 1000\n",
    "\n",
    "#FILTERS\n",
    "FIX_WINDOW = 5 # 1\n",
    "MIN_READ = 1\n",
    "MAX_DIST = 1000\n",
    "MIN_DIST = 0\n",
    "INSWINDOW_FIX = 40 # 15 # 40\n",
    "SHIFT_RESTRICT_SITE = 5 # 3\n",
    "SHIFT_MISS_PRIMER = 60 # 27 # 20 # 12  # >= lenght of primer \n",
    "SHIFT_MISS_RE = 10 # 8\n",
    "WHICH_TAIL = 3 # 5 if 5' repeat tail, 3 if 3' repeat tail\n",
    "\n",
    "#THRESHOLDS\n",
    "RE_HAMMING = 2\n",
    "FLANK_ERRORS = 5\n",
    "REPEAT = 0.8\n",
    "MISS_PRIMER = 4\n",
    "MISS_RE = 2\n",
    "TEMPLATE_SWITCH_MD = 32 # do not used\n",
    "\n",
    "#METACLUSTERING\n",
    "WINDOW = 100\n",
    "MAIN_FLANK_LEN = 14 # template switch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='blue'>1st round</font> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Raw FASTQ files preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start: BC60-L-1000_\n"
     ]
    }
   ],
   "source": [
    "import imp\n",
    "import trimmRE\n",
    "imp.reload(trimmRE)\n",
    "\n",
    "trimmRE.main(inputdir = INPUTDIR,\n",
    "              outputdir = os.path.abspath(OUTPUTDIR) + '/preprocessing/',\n",
    "              primer = PRIMER,\n",
    "              ad1 = AD1,\n",
    "              ad2 = AD2,\n",
    "              blen = BLEN,\n",
    "              shift = SHIFT,\n",
    "              mist = MIST,\n",
    "              restrict_site = RESTRICT_SITE,\n",
    "              re_part = RE,\n",
    "              is_short_flank = IS_SHORT_FLANK,\n",
    "              chaos = CHAOS,\n",
    "              n_core = NCORE,\n",
    "              trimm_n = TRIMM_N,\n",
    "              trimm_poly_N = TRIMM_POLY_N,\n",
    "              poly_n_r1 = POLY_N_R1,\n",
    "              poly_n_r2 = POLY_N_R2,\n",
    "              skip_short_reads = SKIP_SHORT_READS,\n",
    "              mid_mist_short_reads = MID_MIST_SHORT_READS,\n",
    "              end_mist_short_reads = END_MIST_SHORT_READS,\n",
    "              place_of_search_tail = PLACE_OF_SEARCH_TAIL,\n",
    "              min_seq_len_after_trimm = MIN_SEQ_LEN_AFTER_TRIMM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Map FASTQ by BWA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bowtie2 -p 4 -I 25 -X 1000 --dovetail -x /mnt/c/Users/Komar/Lab/UCSC_hg38/ref_bowtie2_index -1 /mnt/c/Users/Komar/Lab/OutPutDir/test_L_2/preprocessing/BC60-L-1000__R1_good.fastq -2 /mnt/c/Users/Komar/Lab/OutPutDir/test_L_2/preprocessing/BC60-L-1000__R2_good.fastq -S /mnt/c/Users/Komar/Lab/OutPutDir/test_L_2/mapping/BC60-L-1000__.sam\n"
     ]
    }
   ],
   "source": [
    "import bwamem\n",
    "imp.reload(bwamem)\n",
    "\n",
    "if MAPPER == 'bowtie2':\n",
    "    mapper_execline = 'bowtie2 -p 4 -I 25 -X 1000 --dovetail'\n",
    "    refway = BOWTIE_INDEX\n",
    "else:\n",
    "    if MAPPER != 'bwa':\n",
    "        print('BWA')\n",
    "    mapper_execline = 'bwa mem -t 4'\n",
    "    refway = BWA_INDEX\n",
    "\n",
    "bwamem.main(inputdir = os.path.abspath(OUTPUTDIR) + '/preprocessing/',\n",
    "            outputdir = os.path.abspath(OUTPUTDIR) + '/mapping/',\n",
    "            refway = refway,\n",
    "            bwaline = mapper_execline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Filter SAM files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start: BC60-L-1000__\n"
     ]
    }
   ],
   "source": [
    "import samfilter_pysam\n",
    "import gline\n",
    "imp.reload(samfilter_pysam)\n",
    "imp.reload(gline)\n",
    "\n",
    "samfilter_pysam.main(inputdir = os.path.abspath(OUTPUTDIR) + '/mapping/',\n",
    "                     outputdir = os.path.abspath(OUTPUTDIR) + '/table/',\n",
    "                     flags = FLAGS, \n",
    "                     n_core = NCORE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Collapse reads by (chr, strand, pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collapser\n",
    "imp.reload(collapser)\n",
    "\n",
    "collapser.main(inputdir = os.path.abspath(OUTPUTDIR) + '/table/',\n",
    "               outputdir = os.path.abspath(OUTPUTDIR) + '/collapse_table/',\n",
    "               target_re = RE,\n",
    "               n_core = NCORE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Create own fix and polymorph ALUBASE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(801703, 8)\n",
      "    CHR      START        END STRAND    NAME R_SITE  R_SITE_POS  IDX\n",
      "0  chr1   67108753   67109046      +    L1P5   GGCC    67109047    0\n",
      "1  chr1   25165803   25166380      +   L1MB5   GGCC    25167050    1\n",
      "2  chr1   50331336   50332274      +    HAL1   GGCC    50332762    2\n",
      "4  chr1  100662981  100669120      -   L1PA4   GGCC   100662661    4\n",
      "5  chr1  176160333  176160805      +  L1PA8A   GGCC   176161047    5\n"
     ]
    }
   ],
   "source": [
    "import exactmatch_fpALU\n",
    "imp.reload(exactmatch_fpALU)\n",
    "\n",
    "exactmatch_fpALU.main(inputdir = os.path.abspath(OUTPUTDIR) + '/collapse_table/',\n",
    "                      outputdir = os.path.abspath(OUTPUTDIR) + '/ematch_table/',\n",
    "                      replibrary = ALU_REF_LIB,\n",
    "                      refway = REF_GENOME,\n",
    "                      restrict_site = RESTRICT_SITE,\n",
    "                      max_dist = MAX_DIST,\n",
    "                      min_dist = MIN_DIST,\n",
    "                      min_read = MIN_READ,\n",
    "                      inswindow = FIX_WINDOW,\n",
    "                      direction = WHICH_TAIL,\n",
    "                      n_core = NCORE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Delete fix and polymorph ALU from reads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import intersection_fpALU\n",
    "imp.reload(intersection_fpALU)\n",
    "\n",
    "intersection_fpALU.main(inputdir = os.path.abspath(OUTPUTDIR) + '/collapse_table/',\n",
    "                        outputdir = os.path.abspath(OUTPUTDIR) + '/notfpALU_table/',\n",
    "                        outputdir_fix = os.path.abspath(OUTPUTDIR) + '/fix_ins_table/',\n",
    "                        replib_inputdir = os.path.abspath(OUTPUTDIR) + '/ematch_table/',\n",
    "                        inswindow = INSWINDOW_FIX,\n",
    "                        fix_ins = None,\n",
    "                        n_core = NCORE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  <font color='blue'>Filters</font> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. Find restrict site around intergration point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import misseq\n",
    "imp.reload(misseq)\n",
    "\n",
    "misseq.main(inputdir = os.path.abspath(OUTPUTDIR) + '/notfpALU_table/',\n",
    "            outputdir = os.path.abspath(OUTPUTDIR) + '/filter_rsite/',\n",
    "            refway = REF_GENOME,\n",
    "            mseq = RESTRICT_SITE,\n",
    "            mname = \"R_SITE\",\n",
    "            shift = SHIFT_RESTRICT_SITE,\n",
    "            n_core = NCORE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. Find primer in flank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import misseq\n",
    "imp.reload(misseq)\n",
    "\n",
    "misseq.main(inputdir = os.path.abspath(OUTPUTDIR) + '/filter_rsite/',\n",
    "            outputdir = os.path.abspath(OUTPUTDIR) + '/filter_primer/',\n",
    "            refway = REF_GENOME,\n",
    "            mseq = PRIMER,\n",
    "            mname = 'MISS_P_HAMMING',\n",
    "            shift = SHIFT_MISS_PRIMER,\n",
    "            n_core = NCORE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9. Find part of RE in flank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import misseq\n",
    "imp.reload(misseq)\n",
    "\n",
    "misseq.main(inputdir = os.path.abspath(OUTPUTDIR) + '/filter_primer/',\n",
    "            outputdir = os.path.abspath(OUTPUTDIR) + '/filter_re/',\n",
    "            refway = REF_GENOME,\n",
    "            mseq = None,\n",
    "            mname = 'MISS_RE_HAMMING',\n",
    "            shift = SHIFT_MISS_RE,\n",
    "            n_core = NCORE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10. Intersect with repeats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import intersection_replib\n",
    "imp.reload(intersection_replib)\n",
    "\n",
    "intersection_replib.main(inputdir = os.path.abspath(OUTPUTDIR) + '/filter_re/',\n",
    "                         outputdir = os.path.abspath(OUTPUTDIR) + '/filter_replib/',\n",
    "                         repeatway = REPEATS_REF_LIB,\n",
    "                         n_core = NCORE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10*. Apply filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import trash_deleting\n",
    "imp.reload(trash_deleting)\n",
    "\n",
    "trash_deleting.main(inputdir = os.path.abspath(OUTPUTDIR) + '/filter_replib/',\n",
    "                    outputdir = os.path.abspath(OUTPUTDIR) + '/pre_metatable/',\n",
    "                    re_hamming = RE_HAMMING,\n",
    "                    flank_errors = FLANK_ERRORS,\n",
    "                    rsite = 'R_SITE',\n",
    "                    repeat = REPEAT,\n",
    "                    m_primer = MISS_PRIMER,\n",
    "                    primer_name = 'P',\n",
    "                    m_re = MISS_RE,\n",
    "                    re_name = 'RE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  <font color='blue'>Metatable</font> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 11. Metaclustering\n",
    "At the clusterisation step all the coordinates of putative insertions from different datasets of the same individual are joined and sorted by value and chromosome. Next, coordinates are grouped with the window size of 100 nt. Putative somatic insertions are identified at this step: insertions with coordinates found in one dataset and absent from all other datasets from the same individual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mPaired:\u001b[0m\n",
      "BC60-L-1000__.txt <----- BC60-L-1000___pcread.txt\n",
      "\n",
      "\n",
      "\u001b[1mUnpaired:\u001b[0m\n",
      "NULL\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import metacluster\n",
    "imp.reload(metacluster)\n",
    "\n",
    "metacluster.main(inputdir = os.path.abspath(OUTPUTDIR) + '/pre_metatable/',\n",
    "                 outputdir = os.path.abspath(OUTPUTDIR) + '/metatable_somatic/',\n",
    "                 pcdir = os.path.abspath(OUTPUTDIR) + '/collapse_table/',\n",
    "                 target_re = RE,\n",
    "                 window = WINDOW,\n",
    "                 blen = BLEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mPaired:\u001b[0m\n",
      "BC60-L-1000__.txt <----- BC60-L-1000___pcread.txt\n",
      "\n",
      "\n",
      "\u001b[1mUnpaired:\u001b[0m\n",
      "NULL\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import metacluster\n",
    "imp.reload(metacluster)\n",
    "\n",
    "metacluster.main(inputdir = os.path.abspath(OUTPUTDIR) + '/fix_ins_table/',\n",
    "                 outputdir = os.path.abspath(OUTPUTDIR) + '/metatable_fix/',\n",
    "                 pcdir = os.path.abspath(OUTPUTDIR) + '/collapse_table/',\n",
    "                 target_re = RE,\n",
    "                 window = WINDOW,\n",
    "                 blen = BLEN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 12. Template switch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bwa aln /mnt/c/Users/Komar/Lab/UCSC_hg38/ref_bwa_index /mnt/c/Users/Komar/Lab/OutPutDir/test_L_2/result_somatic/metatable.fastq > /mnt/c/Users/Komar/Lab/OutPutDir/test_L_2/result_somatic/metatable.sai\n",
      "bwa samse /mnt/c/Users/Komar/Lab/UCSC_hg38/ref_bwa_index /mnt/c/Users/Komar/Lab/OutPutDir/test_L_2/result_somatic/metatable.sai /mnt/c/Users/Komar/Lab/OutPutDir/test_L_2/result_somatic/metatable.fastq > /mnt/c/Users/Komar/Lab/OutPutDir/test_L_2/result_somatic/metatable.sam\n"
     ]
    }
   ],
   "source": [
    "import template_switch\n",
    "imp.reload(template_switch)\n",
    "\n",
    "template_switch.main(inputdir = os.path.abspath(OUTPUTDIR) + '/metatable_somatic/',\n",
    "                     outputdir = os.path.abspath(OUTPUTDIR) + '/result_somatic/',\n",
    "                     primer = PRIMER,\n",
    "                     main_flank_len = MAIN_FLANK_LEN,\n",
    "                     template_switch_md = TEMPLATE_SWITCH_MD,\n",
    "                     refway = BWA_INDEX,\n",
    "                     bwaway = 'bwa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bwa aln /mnt/c/Users/Komar/Lab/UCSC_hg38/ref_bwa_index /mnt/c/Users/Komar/Lab/OutPutDir/test_L_2/result_fix/metatable.fastq > /mnt/c/Users/Komar/Lab/OutPutDir/test_L_2/result_fix/metatable.sai\n",
      "bwa samse /mnt/c/Users/Komar/Lab/UCSC_hg38/ref_bwa_index /mnt/c/Users/Komar/Lab/OutPutDir/test_L_2/result_fix/metatable.sai /mnt/c/Users/Komar/Lab/OutPutDir/test_L_2/result_fix/metatable.fastq > /mnt/c/Users/Komar/Lab/OutPutDir/test_L_2/result_fix/metatable.sam\n"
     ]
    }
   ],
   "source": [
    "import template_switch\n",
    "imp.reload(template_switch)\n",
    "\n",
    "template_switch.main(inputdir = os.path.abspath(OUTPUTDIR) + '/metatable_fix/',\n",
    "                     outputdir = os.path.abspath(OUTPUTDIR) + '/result_fix/',\n",
    "                     primer = PRIMER,\n",
    "                     main_flank_len = MAIN_FLANK_LEN,\n",
    "                     template_switch_md = TEMPLATE_SWITCH_MD,\n",
    "                     refway = BWA_INDEX,\n",
    "                     bwaway = 'bwa')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Result\n",
    "\n",
    "### you can pull output table from 'result' folder in outputdir. Needed file is called 'metatable_ts.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional statistics "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# 0 step\n",
    "df = pd.DataFrame(columns=['art_1', 'art_2', 'art_3', 'art_4', 'art_5'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc['before'] = pd.Series({'art_1': 1000, 'art_2': 1000, 'art_3': 1000, 'art_4': 1000, 'art_5': 1000})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 step: preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = os.path.abspath(OUTPUTDIR) + '/preprocessing/'\n",
    "files = Path(directory).glob('*.txt')\n",
    "i = 0\n",
    "df.loc['trimm'] = pd.Series({'art_1': 0, 'art_2': 0, 'art_3': 0, 'art_4': 0, 'art_5': 0})\n",
    "for file in files:\n",
    "    with open(file, 'r') as f:\n",
    "        df.loc['trimm'][i] = sum(1 for _ in f)\n",
    "        i += 1\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 step: mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = os.path.abspath(OUTPUTDIR) + '/mapping/'\n",
    "files = Path(directory).glob('*.sam')\n",
    "i = 0\n",
    "df.loc['mapping'] = pd.Series({'art_1': 0, 'art_2': 0, 'art_3': 0, 'art_4': 0, 'art_5': 0})\n",
    "for file in files:\n",
    "    with open(file, 'r') as f:\n",
    "        df.loc['mapping'][i] = int(sum(1 if _[0] != '@' else 0 for _ in f) / 2)\n",
    "        i += 1\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 step: filter sam files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = os.path.abspath(OUTPUTDIR) + '/table/'\n",
    "files = Path(directory).glob('*.txt')\n",
    "i = 0\n",
    "df.loc['filter_sam_files'] = pd.Series({'art_1': 0, 'art_2': 0, 'art_3': 0, 'art_4': 0, 'art_5': 0})\n",
    "for file in files:\n",
    "    with open(file, 'r') as f:\n",
    "        df.loc['filter_sam_files'][i] = sum(1 for _ in f) - 1\n",
    "        i += 1\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4 step: collapse reads by (chr, strand, pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = os.path.abspath(OUTPUTDIR) + '/collapse_table/'\n",
    "files = Path(directory).glob('*humanread.txt')\n",
    "i = 0\n",
    "df.loc['grouping'] = pd.Series({'art_1': 0, 'art_2': 0, 'art_3': 0, 'art_4': 0, 'art_5': 0})\n",
    "for file in files:\n",
    "    with open(file, 'r') as f:\n",
    "        df.loc['grouping'][i] = sum(1 for _ in f) - 1\n",
    "        i += 1\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6 step: delete fix and polymorph ALU from reads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = os.path.abspath(OUTPUTDIR) + '/notfpALU_table/'\n",
    "files = Path(directory).glob('*.txt')\n",
    "i = 0\n",
    "df.loc['no_fpALU'] = pd.Series({'art_1': 0, 'art_2': 0, 'art_3': 0, 'art_4': 0, 'art_5': 0})\n",
    "for file in files:\n",
    "    with open(file, 'r') as f:\n",
    "        df.loc['no_fpALU'][i] = sum(1 for _ in f) - 1\n",
    "        i += 1\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7 step: find restrict site around intergration point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = os.path.abspath(OUTPUTDIR) + '/filter_rsite/'\n",
    "files = Path(directory).glob('*.txt')\n",
    "i = 0\n",
    "df.loc['no_rsite'] = pd.Series({'art_1': 0, 'art_2': 0, 'art_3': 0, 'art_4': 0, 'art_5': 0})\n",
    "for file in files:\n",
    "    with open(file, 'r') as f:\n",
    "        df.loc['no_rsite'][i] = sum(1 for _ in f) - 1\n",
    "        #print(file, df.loc['step7'][i])\n",
    "        i += 1\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8 step: find primer in flank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = os.path.abspath(OUTPUTDIR) + '/filter_primer/'\n",
    "files = Path(directory).glob('*.txt')\n",
    "i = 0\n",
    "df.loc['no_flank_primer'] = pd.Series({'art_1': 0, 'art_2': 0, 'art_3': 0, 'art_4': 0, 'art_5': 0})\n",
    "for file in files:\n",
    "    with open(file, 'r') as f:\n",
    "        df.loc['no_flank_primer'][i] = sum(1 for _ in f) - 1\n",
    "        #print(file, df.loc['step8'][i])\n",
    "        i += 1\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9 step: find part of RE in flank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = os.path.abspath(OUTPUTDIR) + '/filter_re/'\n",
    "files = Path(directory).glob('*.txt')\n",
    "i = 0\n",
    "df.loc['no_flank_re'] = pd.Series({'art_1': 0, 'art_2': 0, 'art_3': 0, 'art_4': 0, 'art_5': 0})\n",
    "for file in files:\n",
    "    with open(file, 'r') as f:\n",
    "        df.loc['no_flank_re'][i] = sum(1 for _ in f) - 1\n",
    "        i += 1\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10 step: intersect with repeats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = os.path.abspath(OUTPUTDIR) + '/pre_metatable/'\n",
    "files = Path(directory).glob('*.txt')\n",
    "i = 0\n",
    "df.loc['no_f_repeats'] = pd.Series({'art_1': 0, 'art_2': 0, 'art_3': 0, 'art_4': 0, 'art_5': 0})\n",
    "for file in files:\n",
    "    with open(file, 'r') as f:\n",
    "        df.loc['no_f_repeats'][i] = sum(1 for _ in f) - 1\n",
    "        i += 1\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11 step: metaclustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = os.path.abspath(OUTPUTDIR) + '/metatable_somatic/'\n",
    "files = Path(directory).glob('*humanread.txt')\n",
    "\n",
    "df.loc['metaclustering'] = pd.Series({'art_1': 0, 'art_2': 0, 'art_3': 0, 'art_4': 0, 'art_5': 0})\n",
    "for file in files:\n",
    "    with open(file, 'r') as f:\n",
    "        line = f.readline()\n",
    "        while line != '':\n",
    "            line = f.readline()\n",
    "            if line == '':\n",
    "                break\n",
    "            line = line.split('\\t')[1]\n",
    "            df.loc['metaclustering'][int(line[17]) - 1] += 1\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12 step: template switch control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = os.path.abspath(OUTPUTDIR) + '/result_somatic/'\n",
    "files = Path(directory).glob('*_ts.txt')\n",
    "\n",
    "df.loc['template_switch'] = pd.Series({'art_1': 0, 'art_2': 0, 'art_3': 0, 'art_4': 0, 'art_5': 0})\n",
    "for file in files:\n",
    "    with open(file, 'r') as f:\n",
    "        line = f.readline()\n",
    "        while line != '':\n",
    "            line = f.readline()\n",
    "            if line == '':\n",
    "                break\n",
    "            line = line.split('\\t')[1]\n",
    "            df.loc['template_switch'][int(line[17]) - 1] += 1\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mean = pd.DataFrame(df.mean(axis=0), columns=['num reads'])\n",
    "df_mean['step'] = df_mean.index\n",
    "df_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_percent = pd.DataFrame(df_mean)\n",
    "df_percent['num reads'] = df_mean['num reads'] / df_mean['num reads'][5] * 100\n",
    "df_percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "\n",
    "ax = sns.barplot(x=df_percent['step'].iloc[[5, 6, 7, 8, 9, 11]], \n",
    "                 y=df_percent['num reads'].iloc[[5, 6, 7, 8, 9, 11]], color='grey')\n",
    "\n",
    "ax.bar_label(ax.containers[0])\n",
    "ax.tick_params(axis='x', rotation=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = pd.DataFrame(df['before'], columns=['before', 'after_processing'])\n",
    "new_df['after_processing'] = df['template_switch']\n",
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = pd.read_table(os.path.abspath(OUTPUTDIR) + '/result_somatic/'+'metatable_ts.txt')\n",
    "res.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
